1. 机器学习是对能通过经验自动改进的计算机算法的研究。

2. 分类和回归属于监督学习，之所以称为监督学习，是因为这类算法必须知道预测什么，即目标变量的分类信息。

3. 无监督学习。将数据集合分成由类似的对象组成的多个类的过程称为聚类。

4. 监督学习的用途
   k-近邻算法                   线性回归
   朴素贝叶斯算法               局部加权线性回归
   支持向量机                   Ridge 回归
   决策树                       Lasso 最小回归系数估计
  
5. 无监督学习的用途
   k-均值                       最大期望算法
   DBSCAN                       Parzen 窗设计
   
6. 如何选择合适的算法
   * 使用机器学习算法的目的，想要算法完成何种任务。
   * 需要分析或收集的数据

   预测的话，可以选择监督学习算法。否则，可以选择无监督学习算法。确定选择监督学习算法之后，进一步确定目标变量的类型，离散型的可以选择分类算法；如果是连续型的可以选择回归算法。如果不想预测目标变量的值，则可以选择无监督学习算法。进一步分析是否需要将数据划分为离散的组。如果这是唯一的需求，则使用聚类算法；如果还需要估计数据与每个分组的相似程度，则需要使用密度估计算法。 

7. 开发机器学习应用程序的步骤
   * 收集数据
   * 准备输入数据
   * 分析输入数据
   * 训练算法
   * 测试算法
   * 使用算法

8. 联合概率 
   两件事情同时发生的概率。

9. P(X OR Y) = P(X) + P(Y) -P(X AND Y)
   该公式十分有意义。在AND 和OR 的概率之间搭起了桥梁。

10. 机器学习领域开发的分类算法通常把属性分成为离散的或连续的。

11. k-近邻算法
    优点：精度高、对异常值不敏感、无数据输入假定
    缺点：计算复杂度高、空间复杂度高
    适用范围：数值型和标称型。
    
    k-近邻算法的一般流程
    * 收集数据
    * 准备数据
    * 分析数据
    * 训练算法
    * 测试算法
    * 适用算法

12. k-近邻算法可以完成很多分类任务，但是它最大的缺点就是无法给出数据的内在含义，决策树的主要优势就在于数据形式非常容易理解。

13. 决策树
    * 计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关特性数据。
    * 缺点：可能会产生过度匹配问题
    * 使用数据类型：数值型和标称型

14. 信息增益
    划分数据集的最大原则是：将无序的数据变得更加有序。
    在划分数据集之前之后信息发生的变化称为信息增益，知道如何计算计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。

15.      

    

   














